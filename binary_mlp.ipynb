{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a853139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e8dc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>P100</th>\n",
       "      <th>P41</th>\n",
       "      <th>OspC</th>\n",
       "      <th>DbpA</th>\n",
       "      <th>BmpA</th>\n",
       "      <th>DbpB</th>\n",
       "      <th>P45</th>\n",
       "      <th>P58</th>\n",
       "      <th>P66</th>\n",
       "      <th>VlsE</th>\n",
       "      <th>ErpL</th>\n",
       "      <th>OspD</th>\n",
       "      <th>Diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R49#02</td>\n",
       "      <td>1.983017</td>\n",
       "      <td>2.176121</td>\n",
       "      <td>5.882121</td>\n",
       "      <td>1.738615</td>\n",
       "      <td>1.790831</td>\n",
       "      <td>3.950600</td>\n",
       "      <td>1.065420</td>\n",
       "      <td>1.938904</td>\n",
       "      <td>2.021073</td>\n",
       "      <td>12.455842</td>\n",
       "      <td>1.077889</td>\n",
       "      <td>1.784387</td>\n",
       "      <td>Pos - Late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R49#03</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>2.920710</td>\n",
       "      <td>0.824318</td>\n",
       "      <td>8.279458</td>\n",
       "      <td>5.255024</td>\n",
       "      <td>3.925302</td>\n",
       "      <td>2.137922</td>\n",
       "      <td>9.256009</td>\n",
       "      <td>2.859532</td>\n",
       "      <td>9.868273</td>\n",
       "      <td>1.632559</td>\n",
       "      <td>1.639504</td>\n",
       "      <td>Pos - Late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R49#04</td>\n",
       "      <td>1.303573</td>\n",
       "      <td>2.653693</td>\n",
       "      <td>1.484388</td>\n",
       "      <td>11.072503</td>\n",
       "      <td>2.456271</td>\n",
       "      <td>9.749722</td>\n",
       "      <td>1.851222</td>\n",
       "      <td>3.669641</td>\n",
       "      <td>3.945022</td>\n",
       "      <td>11.615196</td>\n",
       "      <td>2.025580</td>\n",
       "      <td>1.568635</td>\n",
       "      <td>Pos - Late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R49#11</td>\n",
       "      <td>0.951188</td>\n",
       "      <td>1.917436</td>\n",
       "      <td>1.394031</td>\n",
       "      <td>1.197008</td>\n",
       "      <td>1.415143</td>\n",
       "      <td>2.359241</td>\n",
       "      <td>1.012177</td>\n",
       "      <td>1.321336</td>\n",
       "      <td>1.372410</td>\n",
       "      <td>4.370095</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>1.308891</td>\n",
       "      <td>Pos - Early Conv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R49#12</td>\n",
       "      <td>1.117383</td>\n",
       "      <td>2.436597</td>\n",
       "      <td>2.284072</td>\n",
       "      <td>1.397075</td>\n",
       "      <td>1.373926</td>\n",
       "      <td>1.932654</td>\n",
       "      <td>1.233269</td>\n",
       "      <td>1.517965</td>\n",
       "      <td>1.648289</td>\n",
       "      <td>10.357989</td>\n",
       "      <td>1.230867</td>\n",
       "      <td>1.622813</td>\n",
       "      <td>Pos - Early Conv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID      P100       P41      OspC       DbpA      BmpA      DbpB  \\\n",
       "0  R49#02  1.983017  2.176121  5.882121   1.738615  1.790831  3.950600   \n",
       "1  R49#03  0.999950  2.920710  0.824318   8.279458  5.255024  3.925302   \n",
       "2  R49#04  1.303573  2.653693  1.484388  11.072503  2.456271  9.749722   \n",
       "3  R49#11  0.951188  1.917436  1.394031   1.197008  1.415143  2.359241   \n",
       "4  R49#12  1.117383  2.436597  2.284072   1.397075  1.373926  1.932654   \n",
       "\n",
       "        P45       P58       P66       VlsE      ErpL      OspD  \\\n",
       "0  1.065420  1.938904  2.021073  12.455842  1.077889  1.784387   \n",
       "1  2.137922  9.256009  2.859532   9.868273  1.632559  1.639504   \n",
       "2  1.851222  3.669641  3.945022  11.615196  2.025580  1.568635   \n",
       "3  1.012177  1.321336  1.372410   4.370095  0.999341  1.308891   \n",
       "4  1.233269  1.517965  1.648289  10.357989  1.230867  1.622813   \n",
       "\n",
       "               Diag  \n",
       "0        Pos - Late  \n",
       "1        Pos - Late  \n",
       "2        Pos - Late  \n",
       "3  Pos - Early Conv  \n",
       "4  Pos - Early Conv  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\fd299212\\\\Desktop\\\\lab_Stuff\\\\collaborations\\\\cady\\\\machineLearning\\\\lyme_data_20220520.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdee2745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neg                  30\n",
       "Pos - Early Conv     12\n",
       "Pos - Early Acute    12\n",
       "Pos - Late           10\n",
       "Name: Diag, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d3b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bin_diag'] = \"Neg\"\n",
    "df.loc[df['Diag']!=\"Neg\", 'bin_diag'] = \"Pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4e072a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'P100', 'P41', 'OspC', 'DbpA', 'BmpA', 'DbpB', 'P45', 'P58',\n",
       "       'P66', 'VlsE', 'ErpL', 'OspD', 'Diag', 'bin_diag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6bd19c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pos    34\n",
       "Neg    30\n",
       "Name: bin_diag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bin_diag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c226b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['bin_diag'])\n",
    " \n",
    "# printing label\n",
    "#label\n",
    "df[\"state\"]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb574aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create target vector from state column and check top 5 values\n",
    "y = df['state'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be5dbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.45584216,  1.73861454,  1.93890358,  5.88212057,  1.07788947,\n",
       "         2.02107262],\n",
       "       [ 9.86827322,  8.27945815,  9.25600905,  0.82431779,  1.63255897,\n",
       "         2.85953154],\n",
       "       [11.61519582, 11.07250259,  3.66964123,  1.48438828,  2.02558011,\n",
       "         3.94502199],\n",
       "       [ 4.37009458,  1.19700767,  1.32133611,  1.39403148,  0.99934068,\n",
       "         1.3724105 ],\n",
       "       [10.35798884,  1.39707483,  1.51796498,  2.28407202,  1.23086668,\n",
       "         1.64828868]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Originally used all available features but then refined using feature selection techniques\n",
    "#described in the eda (exploratory data analysis notebook)\n",
    "#X = df[['Hum IgG', 'P100', 'P41', 'OspC', 'DbpA', 'BmpA', 'DbpB', 'P45',\n",
    "#       'P58', 'P66', 'VlsE', 'ErpL', 'OspD']].values\n",
    "#X = df[['P100', 'P41', 'OspC', 'DbpA', 'BmpA', 'DbpB', 'P45', 'P58', 'P66', 'VlsE', 'ErpL', 'OspD']].values\n",
    "#X = df[['VlsE', 'DbpA', 'DbpB', 'P58', 'OspC', 'BmpA']].values\n",
    "X = df[['VlsE', 'DbpA', 'P58', 'OspC','ErpL','P66']].values  \n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fec434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.61592421, -0.26375664, -0.23105999,  1.91807338, -0.5546976 ,\n",
       "         0.50556666],\n",
       "       [ 1.90290827,  2.35800234,  4.35997861, -0.32774603,  1.11784959,\n",
       "         1.95119161],\n",
       "       [ 2.38428043,  3.4775352 ,  0.85487261, -0.0346545 ,  2.30296328,\n",
       "         3.82273481],\n",
       "       [ 0.38786108, -0.48084831, -0.61854601, -0.07477569, -0.79155315,\n",
       "        -0.61282106],\n",
       "       [ 2.03785155, -0.40065562, -0.49517335,  0.32042958, -0.09341099,\n",
       "        -0.13716699]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#Data Standardization gives the data zero mean and unit variance, it is good practice, especially for algorithms such as KNN which is based on the distance of data points:\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f43c31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (48, 6) (48,)\n",
      "Test set: (16, 6) (16,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#to provide reproducible pseudo random result, use \"random_state=n\", where n is a numeric value\n",
    "#remove this for a 'more random' result that changes on each invocation\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f7aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(6,), random_state=1)\n",
    "#parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "parameters = {'solver': ['lbfgs','sgd','adam'], 'hidden_layer_sizes':[6,8,10,12], 'max_iter': [2000], 'alpha': [.0001,.001,.01,.1,1] }\n",
    "grid = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, refit=True)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         'hidden_layer_sizes': [6, 8, 10, 12],\n",
       "                         'max_iter': [2000],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b5be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=10, max_iter=2000)\n",
      "{'cv': None, 'error_score': nan, 'estimator__activation': 'relu', 'estimator__alpha': 0.0001, 'estimator__batch_size': 'auto', 'estimator__beta_1': 0.9, 'estimator__beta_2': 0.999, 'estimator__early_stopping': False, 'estimator__epsilon': 1e-08, 'estimator__hidden_layer_sizes': (100,), 'estimator__learning_rate': 'constant', 'estimator__learning_rate_init': 0.001, 'estimator__max_fun': 15000, 'estimator__max_iter': 200, 'estimator__momentum': 0.9, 'estimator__n_iter_no_change': 10, 'estimator__nesterovs_momentum': True, 'estimator__power_t': 0.5, 'estimator__random_state': None, 'estimator__shuffle': True, 'estimator__solver': 'adam', 'estimator__tol': 0.0001, 'estimator__validation_fraction': 0.1, 'estimator__verbose': False, 'estimator__warm_start': False, 'estimator': MLPClassifier(), 'n_jobs': -1, 'param_grid': {'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [6, 8, 10, 12], 'max_iter': [2000], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ee3b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5cce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on train data:  0.9583333333333334\n",
      "score on test data:  0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions_train = clf.predict(X_train)\n",
    "predictions_test = clf.predict(X_test)\n",
    "train_score = accuracy_score(predictions_train, y_train)\n",
    "print(\"score on train data: \", train_score)\n",
    "test_score = accuracy_score(predictions_test, y_test)\n",
    "print(\"score on test data: \", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5728e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22,  2],\n",
       "       [ 0, 24]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Training confusion matrix:')\n",
    "confusion_matrix(predictions_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4fb4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion matrix:\n",
      "[[7 1]\n",
      " [1 7]]\n"
     ]
    }
   ],
   "source": [
    "print('Testing confusion matrix:')\n",
    "cnf_matrix = confusion_matrix(predictions_test, y_test)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d55df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.88      0.88      0.88        16\n",
      "weighted avg       0.88      0.88      0.88        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e93290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b30dfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[7 1]\n",
      " [1 7]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Negative','Pos'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1b4b788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 2\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 3\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 4\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 5\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 6\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 0.857 \n",
      "Run: 7\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 8\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.714 \n",
      "Run: 9\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.857 \n",
      "Run: 10\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 11\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 12\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 13\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 14\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 15\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 16\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.625 \n",
      "Run: 17\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 18\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 19\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 20\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 21\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 0.857 \n",
      "Run: 22\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 23\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.857 \n",
      "Run: 24\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 25\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 26\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 27\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 28\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.857 \n",
      "Run: 29\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 30\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 0.857 \n",
      "Run: 31\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 32\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 33\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 34\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 35\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 36\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 37\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 38\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.571 \n",
      "Run: 39\n",
      " Accuracy: 0.750 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.625 \n",
      "Run: 40\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 41\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 42\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 43\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.857 \n",
      "Run: 44\n",
      " Accuracy: 0.688 \n",
      " Sensitivity: 0.500 \n",
      " Specificity: 0.875 \n",
      "Run: 45\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 0.857 \n",
      "Run: 46\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 47\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 48\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 49\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 50\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.750 \n",
      " Specificity: 1.000 \n",
      "Run: 51\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 0.857 \n",
      "Run: 52\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 53\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 54\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 55\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 56\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 57\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.750 \n",
      " Specificity: 1.000 \n",
      "Run: 58\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 59\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 60\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 61\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 62\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 0.857 \n",
      "Run: 63\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 64\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 65\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 0.750 \n",
      " Specificity: 0.875 \n",
      "Run: 66\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 67\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 68\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 69\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 70\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 71\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 72\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 0.857 \n",
      "Run: 73\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.750 \n",
      " Specificity: 1.000 \n",
      "Run: 74\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 75\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 76\n",
      " Accuracy: 0.812 \n",
      " Sensitivity: 0.667 \n",
      " Specificity: 1.000 \n",
      "Run: 77\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 78\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.750 \n",
      "Run: 79\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 80\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 81\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 82\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 83\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 84\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 85\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 86\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.778 \n",
      " Specificity: 1.000 \n",
      "Run: 87\n",
      " Accuracy: 0.750 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 0.571 \n",
      "Run: 88\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 89\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 90\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 91\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 92\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.750 \n",
      " Specificity: 1.000 \n",
      "Run: 93\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 1.000 \n",
      "Run: 94\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "Run: 95\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 96\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.889 \n",
      " Specificity: 0.857 \n",
      "Run: 97\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 0.875 \n",
      "Run: 98\n",
      " Accuracy: 0.938 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 1.000 \n",
      "Run: 99\n",
      " Accuracy: 0.875 \n",
      " Sensitivity: 0.875 \n",
      " Specificity: 0.875 \n",
      "Run: 100\n",
      " Accuracy: 1.000 \n",
      " Sensitivity: 1.000 \n",
      " Specificity: 1.000 \n",
      "\n",
      "Average Accuracy: 0.914 \n",
      "Average Sensitivity: 0.896 \n",
      "Average Specificity: 0.936 \n"
     ]
    }
   ],
   "source": [
    "#this cell includes code to do 'n' runs of random train/tests on\n",
    "#the whole data set using the best estimator settings from gridsearchCV\n",
    "from sklearn import metrics \n",
    "accuracy_sum = 0\n",
    "sensitivity_sum = 0\n",
    "specificity_sum = 0\n",
    "\n",
    "count = 100\n",
    "new_model = MLPClassifier(alpha=grid.best_estimator_.alpha, hidden_layer_sizes=grid.best_estimator_.hidden_layer_sizes, \n",
    "                          max_iter=grid.best_estimator_.max_iter, solver=grid.best_estimator_.solver)\n",
    "for n in range(1, count+1):\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, stratify=y)   \n",
    "\n",
    "    new_model.fit(X_tr, y_tr)\n",
    "    yh = new_model.predict(X_te)\n",
    "    cr = classification_report(y_te, yh, output_dict=True)\n",
    "    \n",
    "    curr_accuracy = metrics.accuracy_score(y_te,yh)\n",
    "    curr_sensitivity = cr[\"1\"][\"recall\"]\n",
    "    curr_specificity = cr[\"0\"][\"recall\"]\n",
    "    print(\"Run: %d\" % (n))\n",
    "    print(' Accuracy: %.3f ' % (curr_accuracy))\n",
    "    print(' Sensitivity: %.3f ' % (curr_sensitivity))\n",
    "    print(' Specificity: %.3f ' % (curr_specificity))\n",
    "    \n",
    "    sensitivity_sum = sensitivity_sum + curr_sensitivity\n",
    "    specificity_sum = specificity_sum + curr_specificity\n",
    "    accuracy_sum = accuracy_sum + curr_accuracy\n",
    "\n",
    "average_accuracy = accuracy_sum/count\n",
    "average_sensitivity = sensitivity_sum/count\n",
    "average_specificity = specificity_sum/count\n",
    "print('')\n",
    "print('Average Accuracy: %.3f ' % (average_accuracy))\n",
    "print('Average Sensitivity: %.3f ' % (average_sensitivity))\n",
    "print('Average Specificity: %.3f ' % (average_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d456e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc8d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
